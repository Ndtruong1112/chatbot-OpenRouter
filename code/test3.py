import gradio as gr
import time
import requests
from typing import List, Tuple
import openai #lÃ  1 thÆ° viá»‡n cáº§n thiáº¿t Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i OpenRouter
# Cáº¥u hÃ¬nh
API_KEY = "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"
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

# Models Æ°u tiÃªn theo Ä‘á»™ á»•n Ä‘á»‹nh (tá»« cÃ¡c model cÃ³ sáºµn trong log)
PRIORITY_MODELS = [
    "deepseek/deepseek-chat-v3-0324:free",
    "qwen/qwen3-coder:free",
    "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
    "mistralai/mistral-small-3.2-24b-instruct:free",
    "openai/gpt-oss-20b:free",
]

current_model = PRIORITY_MODELS[0] 

print(f"ğŸ”‘ API Key: {API_KEY[:20]}...{API_KEY[-6:]}")
print(f"ğŸ¤– Starting model: {current_model}")

def make_api_call_with_retry(client, model: str, messages: List[dict], max_retries: int = 3):
    """
    Gá»i API vá»›i retry vÃ  timeout handling
    """
    for attempt in range(max_retries):
        try:
            print(f"ğŸ”„ Attempt {attempt + 1}/{max_retries} with model: {model}")
            
            # TÄƒng timeout vÃ  giáº£m tham sá»‘ Ä‘á»ƒ trÃ¡nh timeout
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=1000,      # Giáº£m token Ä‘á»ƒ response nhanh hÆ¡n
                temperature=1,     # Giáº£m creativity Ä‘á»ƒ nhanh hÆ¡n
                timeout=50,          # TÄƒng timeout lÃªn 50s
                extra_headers={
                    "HTTP-Referer": "http://localhost:7862",
                    "X-Title": "Simple ChatBot"
                }
            )
            reply = response.choices[0].message.content
            print(f"âœ… SUCCESS after {attempt + 1} attempts")
            return reply, model
            
        except openai.APITimeoutError as e:
            print(f"â° Timeout on attempt {attempt + 1}: {e}")
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2  # 2s, 4s, 6s
                print(f"ğŸ’¤ Waiting {wait_time}s before retry...")
                time.sleep(wait_time)
            continue
            
        except openai.APIStatusError as e:
            if e.status_code == 408:
                print(f"â° 408 Timeout on attempt {attempt + 1}")
                if attempt < max_retries - 1:
                    time.sleep((attempt + 1) * 3)  # 3s, 6s, 9s
                continue
            else:
                print(f"âŒ API Status Error: {e.status_code} - {e}")
                break
                
        except Exception as e:
            print(f"âŒ Unexpected error on attempt {attempt + 1}: {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
            continue
    
    return None, None

def chat_with_openrouter(message: str, history: List[Tuple[str, str]]):
    """
    HÃ m chat vá»›i handling timeout vÃ  fallback models
    """
    global current_model
    
    print(f"\nğŸ“© New message: {message}")
    
    try:
        client = openai.OpenAI(
            api_key=API_KEY,
            base_url=OPENROUTER_BASE_URL,
            timeout=60.0  # Timeout cho client
        )
        
        # Chuáº©n bá»‹ messages - giá»¯ ngáº¯n gá»n
        messages = [
            {"role": "system", "content": "You are a helpful assistant. Keep responses concise and clear."}
        ]
        
        # Chá»‰ láº¥y 3 tin nháº¯n gáº§n nháº¥t Ä‘á»ƒ trÃ¡nh context quÃ¡ dÃ i
        recent_history = history[-3:] if len(history) > 3 else history
        
        for user_msg, bot_msg in recent_history:
            if user_msg:
                messages.append({"role": "user", "content": user_msg})
            if bot_msg:
                messages.append({"role": "assistant", "content": bot_msg})
        
        messages.append({"role": "user", "content": message})
        
        # Thá»­ vá»›i model hiá»‡n táº¡i trÆ°á»›c
        reply, successful_model = make_api_call_with_retry(client, current_model, messages)
        
        if reply:
            if successful_model != current_model:
                current_model = successful_model
                print(f"ğŸ”„ Switched to model: {current_model}")
            return reply
        
        # Náº¿u model hiá»‡n táº¡i fail, thá»­ cÃ¡c model khÃ¡c
        print("ğŸ”„ Trying fallback models...")
        for fallback_model in PRIORITY_MODELS:
            if fallback_model == current_model:
                continue  # ÄÃ£ thá»­ rá»“i
                
            print(f"ğŸ”„ Trying fallback: {fallback_model}")
            reply, successful_model = make_api_call_with_retry(client, fallback_model, messages, max_retries=2)
            
            if reply:
                current_model = fallback_model
                print(f"âœ… Fallback successful! Switched to: {current_model}")
                return f"[Switched to {current_model}]\n\n{reply}"
        
        # Náº¿u táº¥t cáº£ Ä‘á»u fail
        return "âŒ Táº¥t cáº£ models Ä‘á»u timeout! CÃ³ thá»ƒ do:\nâ€¢ OpenRouter quÃ¡ táº£i\nâ€¢ Káº¿t ná»‘i máº¡ng cháº­m\nâ€¢ Rate limit\n\nğŸ”„ Vui lÃ²ng thá»­ láº¡i sau vÃ i phÃºt."
        
    except Exception as e:
        error_msg = f"âŒ Lá»—i há»‡ thá»‘ng: {str(e)}"
        print(f"ğŸš¨ System error: {e}")
        return error_msg

def get_model_status():
    """Kiá»ƒm tra tráº¡ng thÃ¡i cÃ¡c models"""
    try:
        headers = {"Authorization": f"Bearer {API_KEY}"}
        response = requests.get(f"{OPENROUTER_BASE_URL}/models", headers=headers, timeout=10)
        if response.status_code == 200:
            models_data = response.json()
            available_count = len([m for m in models_data.get('data', []) if 'google' in m.get('id', '')])
            return f"âœ… {available_count} Google models available"
        else:
            return f"âš ï¸ Models API: {response.status_code}"
    except:
        return "âŒ Cannot check models"

# Táº¡o interface
with gr.Blocks(title="ChatBot", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– OpenRouter ChatBot ")
    gr.Markdown(f"**Current Model:** `{current_model}`")
    
    # Status panel
    with gr.Accordion("ğŸ“Š System Status", open=False):
        status_text = gr.Markdown(get_model_status())
        
        def refresh_status():
            return get_model_status()
        
        refresh_btn = gr.Button("ğŸ”„ Refresh Status")
        refresh_btn.click(refresh_status, outputs=status_text)
    
    # Main chat
    chatbot = gr.Chatbot(
        height=500,
        show_copy_button=True,
        avatar_images=("ğŸ‘¤", "ğŸ¤–")
    )
    
    msg = gr.Textbox(
        placeholder="Nháº­p tin nháº¯n ngáº¯n gá»n Ä‘á»ƒ trÃ¡nh timeout...",
        show_label=False,
        max_lines=3
    )
    
    with gr.Row():
        send_btn = gr.Button("ğŸ“¤ Gá»­i", variant="primary")
        clear_btn = gr.Button("ğŸ—‘ï¸ XÃ³a")
        
    # Model selector
    model_dropdown = gr.Dropdown(
        choices=PRIORITY_MODELS,
        value=current_model,
        label="ğŸ¤– Chá»n Model",
        interactive=True
    )
    
    def change_model(new_model):
        global current_model
        current_model = new_model
        return f"ÄÃ£ chuyá»ƒn sang: {new_model}"
    
    def respond(message, chat_history):
        if not message.strip():
            return chat_history, ""
        
        # Hiá»ƒn thá»‹ typing indicator
        thinking_msg = "ğŸ¤” Äang suy nghÄ©..."
        temp_history = chat_history + [(message, thinking_msg)]
        
        try:
            bot_response = chat_with_openrouter(message, chat_history)
            chat_history.append((message, bot_response))
            return chat_history, ""
        except Exception as e:
            error_response = f"âŒ Lá»—i: {str(e)}"
            chat_history.append((message, error_response))
            return chat_history, ""
    
    # Event handlers
    msg.submit(respond, [msg, chatbot], [chatbot, msg])
    send_btn.click(respond, [msg, chatbot], [chatbot, msg])
    clear_btn.click(lambda: [], outputs=chatbot)
    model_dropdown.change(change_model, [model_dropdown], None)
    
    # Examples
    gr.Examples(
        examples=[
            "lÃªn cho a con beat sá»‘ 2",
            "em Äƒn cÆ¡m chÆ°a? ",
            "liá»‡u python cÃ³ pháº£i lÃ  Ä‘á»‰nh xÃ£ há»™i trong thá»i Ä‘áº¡i AI khÃ´ng? ",
            "Ä‘á»™ mixue cÃ³ ngu khÃ´ng? ",
            "36 cÃ³ pháº£i lÃ  1 quá»‘c gia riÃªng khÃ´ng?"
        ],
        inputs=msg
    )

if __name__ == "__main__":
    print("ğŸš€ Starting timeout-fixed chatbot...")
    try:
        demo.launch(
            inbrowser=True,
            share=False,
            server_name="127.0.0.1",
            server_port=7862,  # Äá»•i port trÃ¡nh conflict
            show_error=True,
            debug=False  # Táº¯t debug Ä‘á»ƒ giáº£m overhead
        )
    except Exception as e:
        print(f"âŒ Launch error: {e}")
        demo.launch(inbrowser=True, server_port=0)